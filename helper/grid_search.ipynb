{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search\n",
    "Run separately for each LSTM-backed model one-by-one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from keras.constraints import MaxNorm\n",
    "\n",
    "import keras\n",
    "\n",
    "import os, sys\n",
    "rootpath = \"..\"\n",
    "sys.path.insert(0, f\"{os.getcwd()}/{rootpath}/base_models\")\n",
    "import model_prep\n",
    "\n",
    "step_back = 6  # window size = 6*5 = 30 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_grid_search(building_name, tower_number, season, param_grid, use_delta=True, train_percentage=0.75, shuffle_seed=42):\n",
    "    features = ['FlowEvap', 'PerHumidity', 'TempAmbient', 'TempCondIn',\n",
    "       'TempCondOut', 'TempEvapIn', 'TempEvapOut', 'TempWetBulb',\n",
    "       'PerFreqConP', 'Tonnage','DayOfWeek', 'HourOfDay', 'PerFreqFan']\n",
    "    target = 'EnergyConsumption'\n",
    "\n",
    "    \"\"\"\n",
    "    1. Convert data into a model-compatible shape\n",
    "    \"\"\"\n",
    "\n",
    "    lstm_df, _ = model_prep.create_preprocessed_lstm_df(\n",
    "        building_name=building_name,\n",
    "        tower_number=tower_number,\n",
    "        features=features,\n",
    "        target=target,\n",
    "        season=season,\n",
    "        use_delta=use_delta,\n",
    "    )\n",
    "    if not season:\n",
    "        season = \"allyear\"\n",
    "\n",
    "    \"\"\"\n",
    "    2. Split data into training and testing sets\n",
    "    \"\"\"\n",
    "\n",
    "    X = lstm_df.drop(f\"{target}(t)\", axis=1)  # drop target column\n",
    "    y = lstm_df[f\"{target}(t)\"]  # only have target column\n",
    "\n",
    "    # split into input and outputs\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=(1 - train_percentage), shuffle=True, random_state=shuffle_seed\n",
    "    )\n",
    "\n",
    "    # scale feature data\n",
    "    scaler = MinMaxScaler().fit(X_train)\n",
    "    X_train[X_train.columns] = scaler.transform(X_train)\n",
    "    X_test[X_test.columns] = scaler.transform(X_test)\n",
    "\n",
    "    \"\"\"\n",
    "    3. Get timestepped data as a 3D vector\n",
    "    \"\"\"\n",
    "    vec_X_train = model_prep.df_to_3d(\n",
    "        lstm_dtframe=X_train, num_columns=len(features) + 1, step_back=step_back\n",
    "    )\n",
    "    vec_X_test = model_prep.df_to_3d(\n",
    "        lstm_dtframe=X_test, num_columns=len(features) + 1, step_back=step_back\n",
    "    )\n",
    "\n",
    "    vec_y_train = y_train.values\n",
    "    vec_y_test = y_test.values\n",
    "\n",
    "    \"\"\"\n",
    "    4. Create and Train model\n",
    "    \"\"\"\n",
    "    # Create a function that builds the Keras model\n",
    "    def create_model(dropout_rate = 0.0, weight_constraint = 2.0, lstmcells = 32, activation = 'tanh', optimizer = \"Adamax\"):\n",
    "        model = keras.models.Sequential()\n",
    "        model.add(\n",
    "            keras.layers.LSTM(\n",
    "                lstmcells,\n",
    "                input_shape=(vec_X_train.shape[1], vec_X_train.shape[2]),\n",
    "                kernel_constraint=MaxNorm(weight_constraint),\n",
    "                recurrent_dropout=dropout_rate,\n",
    "                activation=activation\n",
    "            )\n",
    "        )\n",
    "        model.add(keras.layers.Dense(1))\n",
    "        model.compile(loss='mse', optimizer=optimizer)\n",
    "        return model\n",
    "\n",
    "    # Create a KerasClassifier\n",
    "    model = KerasRegressor(build_fn=create_model, loss=\"mse\", verbose=0)\n",
    "\n",
    "    # Create GridSearchCV and perform the grid search\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=3)\n",
    "    grid_result = grid_search.fit(vec_X_train, vec_y_train)\n",
    "\n",
    "    # summarize results\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "    print(grid_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = [32, 64, 72, 128] # selecting 32\n",
    "epochs = [50, 100, 200]  # selecting 200\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "run_grid_search(building_name=\"ESB\", tower_number=1, season=\"summer\", param_grid=param_grid)\n",
    "\n",
    "# dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "# weight_constraint = [1.0, 2.0, 3.0, 4.0, 5.0]\n",
    "# neurons = [6, 16, 32, 64, 128]\n",
    "# lstmcells = [1, 6, 16, 32, 64]\n",
    "# activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "# param_grid = dict(model__dropout_rate=dropout_rate, model__weight_constraint=weight_constraint)\n",
    "# param_grid = dict(model__activation=activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_grid_search(building_name, tower_number, season, param_grid, use_delta=True, train_percentage=0.75, shuffle_seed=42):\n",
    "    features = ['FlowEvap', 'PerHumidity', 'TempAmbient', 'TempCondIn',\n",
    "       'TempCondOut', 'TempEvapIn', 'TempEvapOut', 'TempWetBulb',\n",
    "       'PerFreqConP', 'Tonnage','DayOfWeek', 'HourOfDay', 'PerFreqFan']\n",
    "    target = 'EnergyConsumption'\n",
    "\n",
    "    \"\"\"\n",
    "    1. Convert data into a model-compatible shape\n",
    "    \"\"\"\n",
    "\n",
    "    lstm_df, _ = model_prep.create_preprocessed_lstm_df(\n",
    "        building_name=building_name,\n",
    "        tower_number=tower_number,\n",
    "        features=features,\n",
    "        target=target,\n",
    "        season=season,\n",
    "        use_delta=use_delta,\n",
    "    )\n",
    "    if not season:\n",
    "        season = \"allyear\"\n",
    "\n",
    "    \"\"\"\n",
    "    2. Split data into training and testing sets\n",
    "    \"\"\"\n",
    "\n",
    "    X = lstm_df.drop(f\"{target}(t)\", axis=1)  # drop target column\n",
    "    y = lstm_df[f\"{target}(t)\"]  # only have target column\n",
    "\n",
    "    # split into input and outputs\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=(1 - train_percentage), shuffle=True, random_state=shuffle_seed\n",
    "    )\n",
    "\n",
    "    # scale feature data\n",
    "    scaler = MinMaxScaler().fit(X_train)\n",
    "    X_train[X_train.columns] = scaler.transform(X_train)\n",
    "    X_test[X_test.columns] = scaler.transform(X_test)\n",
    "\n",
    "    \"\"\"\n",
    "    3. Get timestepped data as a 3D vector\n",
    "    \"\"\"\n",
    "    vec_X_train = model_prep.df_to_3d(\n",
    "        lstm_dtframe=X_train, num_columns=len(features) + 1, step_back=step_back\n",
    "    )\n",
    "    vec_X_test = model_prep.df_to_3d(\n",
    "        lstm_dtframe=X_test, num_columns=len(features) + 1, step_back=step_back\n",
    "    )\n",
    "\n",
    "    vec_y_train = y_train.values\n",
    "    vec_y_test = y_test.values\n",
    "\n",
    "    \"\"\"\n",
    "    4. Create and Train model\n",
    "    \"\"\"\n",
    "    # Create a function that builds the Keras model\n",
    "    def create_model(dropout_rate = 0.0, weight_constraint = 2.0, lstmcells = 32, activation = 'tanh'):\n",
    "        model = keras.models.Sequential()\n",
    "        model.add(\n",
    "            keras.layers.LSTM(\n",
    "                lstmcells,\n",
    "                input_shape=(vec_X_train.shape[1], vec_X_train.shape[2]),\n",
    "                kernel_constraint=MaxNorm(weight_constraint),\n",
    "                recurrent_dropout=dropout_rate,\n",
    "                activation=activation\n",
    "            )\n",
    "        )\n",
    "        model.add(keras.layers.Dense(1))\n",
    "        return model\n",
    "\n",
    "    # Create a KerasClassifier\n",
    "    model = KerasRegressor(build_fn=create_model, loss=\"mse\", batch_size=32, epochs=200, verbose=0)\n",
    "\n",
    "    # Create GridSearchCV and perform the grid search\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=3)\n",
    "    grid_result = grid_search.fit(vec_X_train, vec_y_train)\n",
    "\n",
    "    # summarize results\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "    print(grid_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax'] # selecting Adam\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "run_grid_search(building_name=\"ESB\", tower_number=1, season=\"summer\", param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_grid_search(building_name, tower_number, season, param_grid, use_delta=True, train_percentage=0.75, shuffle_seed=42):\n",
    "    features = ['FlowEvap', 'PerHumidity', 'TempAmbient', 'TempCondIn',\n",
    "       'TempCondOut', 'TempEvapIn', 'TempEvapOut', 'TempWetBulb',\n",
    "       'PerFreqConP', 'Tonnage','DayOfWeek', 'HourOfDay', 'PerFreqFan']\n",
    "    target = 'EnergyConsumption'\n",
    "\n",
    "    \"\"\"\n",
    "    1. Convert data into a model-compatible shape\n",
    "    \"\"\"\n",
    "\n",
    "    lstm_df, _ = model_prep.create_preprocessed_lstm_df(\n",
    "        building_name=building_name,\n",
    "        tower_number=tower_number,\n",
    "        features=features,\n",
    "        target=target,\n",
    "        season=season,\n",
    "        use_delta=use_delta,\n",
    "    )\n",
    "    if not season:\n",
    "        season = \"allyear\"\n",
    "\n",
    "    \"\"\"\n",
    "    2. Split data into training and testing sets\n",
    "    \"\"\"\n",
    "\n",
    "    X = lstm_df.drop(f\"{target}(t)\", axis=1)  # drop target column\n",
    "    y = lstm_df[f\"{target}(t)\"]  # only have target column\n",
    "\n",
    "    # split into input and outputs\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=(1 - train_percentage), shuffle=True, random_state=shuffle_seed\n",
    "    )\n",
    "\n",
    "    # scale feature data\n",
    "    scaler = MinMaxScaler().fit(X_train)\n",
    "    X_train[X_train.columns] = scaler.transform(X_train)\n",
    "    X_test[X_test.columns] = scaler.transform(X_test)\n",
    "\n",
    "    \"\"\"\n",
    "    3. Get timestepped data as a 3D vector\n",
    "    \"\"\"\n",
    "    vec_X_train = model_prep.df_to_3d(\n",
    "        lstm_dtframe=X_train, num_columns=len(features) + 1, step_back=step_back\n",
    "    )\n",
    "    vec_X_test = model_prep.df_to_3d(\n",
    "        lstm_dtframe=X_test, num_columns=len(features) + 1, step_back=step_back\n",
    "    )\n",
    "\n",
    "    vec_y_train = y_train.values\n",
    "    vec_y_test = y_test.values\n",
    "\n",
    "    \"\"\"\n",
    "    4. Create and Train model\n",
    "    \"\"\"\n",
    "    # Create a function that builds the Keras model\n",
    "    def create_model(activation, dropout_rate = 0.0, weight_constraint = 2.0, lstmcells = 32, optimizer = \"Adam\"):\n",
    "        model = keras.models.Sequential()\n",
    "        model.add(\n",
    "            keras.layers.LSTM(\n",
    "                lstmcells,\n",
    "                input_shape=(vec_X_train.shape[1], vec_X_train.shape[2]),\n",
    "                kernel_constraint=MaxNorm(weight_constraint),\n",
    "                recurrent_dropout=dropout_rate,\n",
    "                activation=activation\n",
    "            )\n",
    "        )\n",
    "        model.add(keras.layers.Dense(1))\n",
    "        model.compile(loss='mse', optimizer=optimizer)\n",
    "        return model\n",
    "\n",
    "    # Create a KerasClassifier\n",
    "    model = KerasRegressor(build_fn=create_model, loss=\"mse\", verbose=0)\n",
    "\n",
    "    # Create GridSearchCV and perform the grid search\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=3)\n",
    "    grid_result = grid_search.fit(vec_X_train, vec_y_train)\n",
    "\n",
    "    # summarize results\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "    print(grid_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = ['relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'] # selecting relu\n",
    "param_grid = dict(model__activation=activation)\n",
    "run_grid_search(building_name=\"ESB\", tower_number=1, season=\"summer\", param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_grid_search(building_name, tower_number, season, param_grid, use_delta=True, train_percentage=0.75, shuffle_seed=42):\n",
    "    features = ['FlowEvap', 'PerHumidity', 'TempAmbient', 'TempCondIn',\n",
    "       'TempCondOut', 'TempEvapIn', 'TempEvapOut', 'TempWetBulb',\n",
    "       'PerFreqConP', 'Tonnage','DayOfWeek', 'HourOfDay', 'PerFreqFan']\n",
    "    target = 'EnergyConsumption'\n",
    "\n",
    "    \"\"\"\n",
    "    1. Convert data into a model-compatible shape\n",
    "    \"\"\"\n",
    "\n",
    "    lstm_df, _ = model_prep.create_preprocessed_lstm_df(\n",
    "        building_name=building_name,\n",
    "        tower_number=tower_number,\n",
    "        features=features,\n",
    "        target=target,\n",
    "        season=season,\n",
    "        use_delta=use_delta,\n",
    "    )\n",
    "    if not season:\n",
    "        season = \"allyear\"\n",
    "\n",
    "    \"\"\"\n",
    "    2. Split data into training and testing sets\n",
    "    \"\"\"\n",
    "\n",
    "    X = lstm_df.drop(f\"{target}(t)\", axis=1)  # drop target column\n",
    "    y = lstm_df[f\"{target}(t)\"]  # only have target column\n",
    "\n",
    "    # split into input and outputs\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=(1 - train_percentage), shuffle=True, random_state=shuffle_seed\n",
    "    )\n",
    "\n",
    "    # scale feature data\n",
    "    scaler = MinMaxScaler().fit(X_train)\n",
    "    X_train[X_train.columns] = scaler.transform(X_train)\n",
    "    X_test[X_test.columns] = scaler.transform(X_test)\n",
    "\n",
    "    \"\"\"\n",
    "    3. Get timestepped data as a 3D vector\n",
    "    \"\"\"\n",
    "    vec_X_train = model_prep.df_to_3d(\n",
    "        lstm_dtframe=X_train, num_columns=len(features) + 1, step_back=step_back\n",
    "    )\n",
    "    vec_X_test = model_prep.df_to_3d(\n",
    "        lstm_dtframe=X_test, num_columns=len(features) + 1, step_back=step_back\n",
    "    )\n",
    "\n",
    "    vec_y_train = y_train.values\n",
    "    vec_y_test = y_test.values\n",
    "\n",
    "    \"\"\"\n",
    "    4. Create and Train model\n",
    "    \"\"\"\n",
    "    # Create a function that builds the Keras model\n",
    "    def create_model(lstmcells, activation=\"relu\", dropout_rate = 0.0, weight_constraint = 2.0, optimizer = \"Adam\"):\n",
    "        model = keras.models.Sequential()\n",
    "        model.add(\n",
    "            keras.layers.LSTM(\n",
    "                lstmcells,\n",
    "                input_shape=(vec_X_train.shape[1], vec_X_train.shape[2]),\n",
    "                kernel_constraint=MaxNorm(weight_constraint),\n",
    "                recurrent_dropout=dropout_rate,\n",
    "                activation=activation\n",
    "            )\n",
    "        )\n",
    "        model.add(keras.layers.Dense(1))\n",
    "        model.compile(loss='mse', optimizer=optimizer)\n",
    "        return model\n",
    "\n",
    "    # Create a KerasClassifier\n",
    "    model = KerasRegressor(build_fn=create_model, loss=\"mse\", verbose=0)\n",
    "\n",
    "    # Create GridSearchCV and perform the grid search\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=3)\n",
    "    grid_result = grid_search.fit(vec_X_train, vec_y_train)\n",
    "\n",
    "    # summarize results\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "    print(grid_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = dict(model__lstmcells=[16, 32, 64, 128]) # selecting 64\n",
    "run_grid_search(building_name=\"ESB\", tower_number=1, season=\"summer\", param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_grid_search(building_name, tower_number, season, param_grid, use_delta=True, train_percentage=0.75, shuffle_seed=42):\n",
    "    features = ['FlowEvap', 'PerHumidity', 'TempAmbient', 'TempCondIn',\n",
    "       'TempCondOut', 'TempEvapIn', 'TempEvapOut', 'TempWetBulb',\n",
    "       'PerFreqConP', 'Tonnage','DayOfWeek', 'HourOfDay', 'PerFreqFan']\n",
    "    target = 'EnergyConsumption'\n",
    "\n",
    "    \"\"\"\n",
    "    1. Convert data into a model-compatible shape\n",
    "    \"\"\"\n",
    "\n",
    "    lstm_df, _ = model_prep.create_preprocessed_lstm_df(\n",
    "        building_name=building_name,\n",
    "        tower_number=tower_number,\n",
    "        features=features,\n",
    "        target=target,\n",
    "        season=season,\n",
    "        use_delta=use_delta,\n",
    "    )\n",
    "    if not season:\n",
    "        season = \"allyear\"\n",
    "\n",
    "    \"\"\"\n",
    "    2. Split data into training and testing sets\n",
    "    \"\"\"\n",
    "\n",
    "    X = lstm_df.drop(f\"{target}(t)\", axis=1)  # drop target column\n",
    "    y = lstm_df[f\"{target}(t)\"]  # only have target column\n",
    "\n",
    "    # split into input and outputs\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=(1 - train_percentage), shuffle=True, random_state=shuffle_seed\n",
    "    )\n",
    "\n",
    "    # scale feature data\n",
    "    scaler = MinMaxScaler().fit(X_train)\n",
    "    X_train[X_train.columns] = scaler.transform(X_train)\n",
    "    X_test[X_test.columns] = scaler.transform(X_test)\n",
    "\n",
    "    \"\"\"\n",
    "    3. Get timestepped data as a 3D vector\n",
    "    \"\"\"\n",
    "    vec_X_train = model_prep.df_to_3d(\n",
    "        lstm_dtframe=X_train, num_columns=len(features) + 1, step_back=step_back\n",
    "    )\n",
    "    vec_X_test = model_prep.df_to_3d(\n",
    "        lstm_dtframe=X_test, num_columns=len(features) + 1, step_back=step_back\n",
    "    )\n",
    "\n",
    "    vec_y_train = y_train.values\n",
    "    vec_y_test = y_test.values\n",
    "\n",
    "    \"\"\"\n",
    "    4. Create and Train model\n",
    "    \"\"\"\n",
    "    # Create a function that builds the Keras model\n",
    "    def create_model(dropout_rate, weight_constraint, lstmcells=64, activation=\"relu\", optimizer = \"Adam\"):\n",
    "        model = keras.models.Sequential()\n",
    "        model.add(\n",
    "            keras.layers.LSTM(\n",
    "                lstmcells,\n",
    "                input_shape=(vec_X_train.shape[1], vec_X_train.shape[2]),\n",
    "                kernel_constraint=MaxNorm(weight_constraint),\n",
    "                recurrent_dropout=dropout_rate,\n",
    "                activation=activation\n",
    "            )\n",
    "        )\n",
    "        model.add(keras.layers.Dense(1))\n",
    "        model.compile(loss='mse', optimizer=optimizer)\n",
    "        return model\n",
    "\n",
    "    # Create a KerasClassifier\n",
    "    model = KerasRegressor(build_fn=create_model, loss=\"mse\", verbose=0)\n",
    "\n",
    "    # Create GridSearchCV and perform the grid search\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=3)\n",
    "    grid_result = grid_search.fit(vec_X_train, vec_y_train)\n",
    "\n",
    "    # summarize results\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "    print(grid_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_constraint = [1.0, 2.0, 3.0, 4.0, 5.0] # select 0.0\n",
    "dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9] # select 4.0\n",
    "param_grid = dict(model__dropout_rate=dropout_rate, model__weight_constraint=weight_constraint)\n",
    "run_grid_search(building_name=\"ESB\", tower_number=1, season=\"summer\", param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_grid_search(building_name, tower_number, season, param_grid, use_delta=True, train_percentage=0.75, shuffle_seed=42):\n",
    "    features = ['FlowEvap', 'PerHumidity', 'TempAmbient', 'TempCondIn',\n",
    "       'TempCondOut', 'TempEvapIn', 'TempEvapOut', 'TempWetBulb',\n",
    "       'PerFreqConP', 'Tonnage','DayOfWeek', 'HourOfDay', 'PerFreqFan']\n",
    "    target = 'EnergyConsumption'\n",
    "\n",
    "    \"\"\"\n",
    "    1. Convert data into a model-compatible shape\n",
    "    \"\"\"\n",
    "\n",
    "    lstm_df, _ = model_prep.create_preprocessed_lstm_df(\n",
    "        building_name=building_name,\n",
    "        tower_number=tower_number,\n",
    "        features=features,\n",
    "        target=target,\n",
    "        season=season,\n",
    "        use_delta=use_delta,\n",
    "        step_back=6\n",
    "    )\n",
    "    if not season:\n",
    "        season = \"allyear\"\n",
    "\n",
    "    \"\"\"\n",
    "    2. Split data into training and testing sets\n",
    "    \"\"\"\n",
    "\n",
    "    X = lstm_df.drop(f\"{target}(t)\", axis=1)  # drop target column\n",
    "    y = lstm_df[f\"{target}(t)\"]  # only have target column\n",
    "\n",
    "    # split into input and outputs\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=(1 - train_percentage), shuffle=True, random_state=shuffle_seed\n",
    "    )\n",
    "\n",
    "    # scale feature data\n",
    "    scaler = MinMaxScaler().fit(X_train)\n",
    "    X_train[X_train.columns] = scaler.transform(X_train)\n",
    "    X_test[X_test.columns] = scaler.transform(X_test)\n",
    "\n",
    "    \"\"\"\n",
    "    3. Get timestepped data as a 3D vector\n",
    "    \"\"\"\n",
    "    vec_X_train = model_prep.df_to_3d(\n",
    "        lstm_dtframe=X_train, num_columns=len(features) + 1, step_back=step_back\n",
    "    )\n",
    "    vec_X_test = model_prep.df_to_3d(\n",
    "        lstm_dtframe=X_test, num_columns=len(features) + 1, step_back=step_back\n",
    "    )\n",
    "\n",
    "    vec_y_train = y_train.values\n",
    "    vec_y_test = y_test.values\n",
    "\n",
    "    \"\"\"\n",
    "    4. Create and Train model\n",
    "    \"\"\"\n",
    "    # Create a function that builds the Keras model\n",
    "    def create_model(step_back, dropout_rate=0.0, weight_constraint=4.0, lstmcells=64, activation=\"relu\", optimizer = \"Adam\"):\n",
    "        model = keras.models.Sequential()\n",
    "        model.add(\n",
    "            keras.layers.LSTM(\n",
    "                lstmcells,\n",
    "                input_shape=(vec_X_train.shape[1], vec_X_train.shape[2]),\n",
    "                kernel_constraint=MaxNorm(weight_constraint),\n",
    "                recurrent_dropout=dropout_rate,\n",
    "                activation=activation\n",
    "            )\n",
    "        )\n",
    "        model.add(keras.layers.Dense(1))\n",
    "        model.compile(loss='mse', optimizer=optimizer)\n",
    "        return model\n",
    "\n",
    "    # Create a KerasClassifier\n",
    "    model = KerasRegressor(build_fn=create_model, loss=\"mse\", verbose=0)\n",
    "\n",
    "    # Create GridSearchCV and perform the grid search\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=3)\n",
    "    grid_result = grid_search.fit(vec_X_train, vec_y_train)\n",
    "\n",
    "    # summarize results\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "    print(grid_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = dict(model__step_back=[1, 3, 6, 12, 24]) # selecting step_back = 6\n",
    "\n",
    "# Call the run_grid_search function with the modified param_grid\n",
    "run_grid_search(building_name=\"ESB\", tower_number=1, season=\"summer\", param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "batch size: 32\n",
    "epochs: 200\n",
    "optimizer: Adam\n",
    "dropout rate: 0.0\n",
    "weight constraints: 4.0\n",
    "step_back: 6\n",
    "lstm cells: 64\n",
    "activation: relu\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
