{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search\n",
    "For MLP model in seasonality adjustment methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 01:01:49.331153: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Load Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "import warnings\n",
    "from typing import List\n",
    "import os, sys, time\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import keras\n",
    "\n",
    "rootpath = \"..\"\n",
    "sys.path.insert(0, f\"{os.getcwd()}/{rootpath}/base_models\")\n",
    "sys.path.insert(0, f\"{os.getcwd()}/{rootpath}/source_models\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import model_prep\n",
    "\n",
    "\n",
    "step_back = 6  # window size = 6*5 = 30 mins\n",
    "\n",
    "step_back = 6  # window size = 6*5 = 30 mins\n",
    "season_map = {\n",
    "    \"spring\": [3, 4, 5],\n",
    "    \"summer\": [6, 7, 8],\n",
    "    \"fall\": [9, 10, 11],\n",
    "    \"winter\": [12, 1, 2],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_building_name = \"ESB\"\n",
    "from_tower_number = 1\n",
    "to_building_name = \"ESB\"\n",
    "to_tower_number = 2\n",
    "features = ['FlowEvap', 'PerHumidity', 'TempAmbient', 'TempCondIn',\n",
    "    'TempCondOut', 'TempEvapIn', 'TempEvapOut', 'TempWetBulb',\n",
    "    'PerFreqConP', 'Tonnage', 'PerFreqFan']\n",
    "target = 'EnergyConsumption'\n",
    "to_season = \"summer\"\n",
    "from_season = \"summer\"\n",
    "finetuning_percentage = 0.8\n",
    "source_epochs=100\n",
    "finetune_epochs = 100\n",
    "display_results = True\n",
    "use_delta = True\n",
    "shuffle_seed = 42\n",
    "train_percentage = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. Load data and do basic preprocessing\n",
    "\"\"\"\n",
    "# load data\n",
    "df = pd.read_csv(\n",
    "    f\"{rootpath}/data/{from_building_name.lower()}/{from_building_name.lower()}{from_tower_number}_preprocessed.csv\",\n",
    "    index_col=\"time\",\n",
    ")\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "# only take data for one season\n",
    "df = model_prep.choose_season(df, season=from_season)\n",
    "\n",
    "# remove cases in which tower was OFF, and cases where OFF data would be included in past timesteps of ON data\n",
    "on_condition = df[target] > 0\n",
    "df = df.drop(df[~on_condition].index, axis=0)\n",
    "\n",
    "# select features and targets and create final dataframe that includes only relevant features and targets\n",
    "df = df[features+[\"DayOfWeek\"]].join(df[target], on=df.index)\n",
    "\n",
    "# if difference from first value should be used as for predictions then return the first value\n",
    "first_val = df.iloc[0, df.columns.get_loc(target)]\n",
    "if use_delta:\n",
    "    df[target] = (\n",
    "        df[target] - first_val\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "2. Seasonality removal\n",
    "\"\"\"\n",
    "\n",
    "def calculate_seasonal_index(time_series, seasonality_column, m):\n",
    "    \"\"\"\n",
    "    Calculate the seasonal index for each seasonality value in the time series.\n",
    "\n",
    "    Parameters:\n",
    "    - time_series: Pandas DataFrame containing the time series data with a column for the seasonality values.\n",
    "    - seasonality_column: String representing the column name containing the seasonality values (e.g., days of the week).\n",
    "    - m: Integer representing the number of data points for each seasonality value.\n",
    "\n",
    "    Returns:\n",
    "    - Pandas DataFrame containing the seasonal index for each seasonality value.\n",
    "    \"\"\"\n",
    "\n",
    "    # Group the data by the seasonality column\n",
    "    grouped_data = time_series.groupby(seasonality_column)\n",
    "\n",
    "    # Calculate the average of all target variable data points\n",
    "    y_bar = time_series.mean()[target]\n",
    "\n",
    "    # Initialize an empty dictionary to store the seasonal index values\n",
    "    seasonal_index_dict = {}\n",
    "\n",
    "    # Iterate through each group (seasonality value)\n",
    "    for group, group_data in grouped_data:\n",
    "        # Calculate the sum of the first m data points\n",
    "        sum_y_p_j = group_data.iloc[:m][target].sum()\n",
    "\n",
    "        # Calculate the seasonal index using the provided formula\n",
    "        seasonal_index = 1 / y_bar * (1 / m) * sum_y_p_j\n",
    "\n",
    "        # Store the seasonal index value in the dictionary\n",
    "        seasonal_index_dict[group] = seasonal_index\n",
    "\n",
    "    # Convert the dictionary to a Pandas DataFrame\n",
    "    seasonal_index_df = pd.DataFrame(list(seasonal_index_dict.items()), columns=[seasonality_column, 'sp'])\n",
    "\n",
    "    return seasonal_index_df\n",
    "\n",
    "def operate_with_sp(col, sp_df, operation):\n",
    "    index_col = col.index\n",
    "    combined_df = pd.merge(col, sp_df, left_on=col.index.dayofweek, right_on='DayOfWeek', how='left').set_index(index_col)\n",
    "    if operation == 'multiply':\n",
    "        combined_df[col.name] = combined_df[col.name] * combined_df['sp']\n",
    "    elif operation == 'divide':\n",
    "        combined_df[col.name] = combined_df[col.name] / combined_df['sp']\n",
    "    else:\n",
    "        raise ValueError('Invalid operation')\n",
    "    return combined_df[col.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply seasonality removal\n",
    "sdf = calculate_seasonal_index(df, 'DayOfWeek', 7)\n",
    "df[target] = operate_with_sp(df[target], sdf, 'divide')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "3. Split data into training and testing sets\n",
    "\"\"\"\n",
    "\n",
    "df = df.dropna() # drop first NaN value due to zero division\n",
    "X = df[features]  # only have features\n",
    "y = df[target]  # only have target column\n",
    "\n",
    "# split into input and outputs\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=(1 - train_percentage), shuffle=False, random_state=shuffle_seed\n",
    ")\n",
    "\n",
    "# scale feature data\n",
    "scaler = MinMaxScaler().fit(X_train)\n",
    "X_train[X_train.columns] = scaler.transform(X_train)\n",
    "X_test[X_test.columns] = scaler.transform(X_test)\n",
    "vec_X_train = X_train.values\n",
    "vec_X_test = X_test.values\n",
    "\n",
    "\n",
    "vec_y_train = y_train.values\n",
    "vec_y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'batch_size': 10, 'epochs': 200, 'units': 80}\n",
      "Best MAE found:  71.07040794588964\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Function to create the Keras model\n",
    "def create_model(units=20):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units, input_shape=(len(features),), kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(units=1, activation='linear'))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Wrap the Keras model so it can be used by scikit-learn\n",
    "keras_regressor = KerasRegressor(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "\n",
    "# Define the hyperparameters to search\n",
    "param_grid = {\n",
    "    'units': [30, 80],  # Number of units in the first layer\n",
    "    'batch_size': [10],  # Batch size\n",
    "    'epochs': [200]  # Number of training epochs\n",
    "}\n",
    "\n",
    "# Use GridSearchCV to find the best hyperparameters\n",
    "grid = GridSearchCV(estimator=keras_regressor, param_grid=param_grid, scoring='neg_mean_absolute_error', cv=KFold(n_splits=3))\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and corresponding MSE\n",
    "print(\"Best parameters found: \", grid_result.best_params_)\n",
    "print(\"Best MAE found: \", -grid_result.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters found:  {'batch_size': 10, 'epochs': 200, 'units': 30}\n",
    "Best MAE found:  70.4610976722637\n",
    "\n",
    "Best parameters found:  {'batch_size': 10, 'epochs': 200, 'units': 80}\n",
    "Best MAE found:  70.49244807956524\n",
    "\n",
    "Best parameters found:  {'batch_size': 10, 'epochs': 200, 'units': 80}\n",
    "Best MAE found:  71.07040794588964"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
