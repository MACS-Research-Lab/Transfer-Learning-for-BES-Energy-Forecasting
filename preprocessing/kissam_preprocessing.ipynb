{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#27469c\">Preprocessing of Kissam Cooling Towers 1 and 2 data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import preprocessor\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "rootpath = \"..\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cooling tower data\n",
    "df = pd.read_csv(f'{rootpath}/data/kissam/2661_x.csv', index_col='time')\n",
    "df.index = pd.to_datetime(df.index, utc='True')\n",
    "\n",
    "for df_name in [\"1510_x\", \"1509_2\", \"1482_1\", \"4684_1\", \"4685_2\"]:\n",
    "    more_data = pd.read_csv(f'{rootpath}/data/kissam/{df_name}.csv', index_col='time')\n",
    "    more_data.index = pd.to_datetime(df.index, utc='True')\n",
    "    df = pd.concat([df, more_data], axis=1)\n",
    "\n",
    "df.drop(columns=df.filter(like='generated', axis=1).columns, inplace=True)\n",
    "df = df.loc[:,~df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.loc[:, ~df.columns.str.contains(\"2\")]\n",
    "df2 = df.loc[:, ~df.columns.str.contains(\"1\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#27469c\">Rename columns and separate the 2 cooling towers' data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1,2]:\n",
    "    renaming = {}\n",
    "    renaming[\"TempWetBulb\"] = \"TempWetBulb\"\n",
    "    renaming[\"TempAmbient\"] = \"TempAmbient\"\n",
    "    renaming[f\"CT_{i}.TempCondIn\"] = \"TempCondIn\"\n",
    "    renaming[f\"CT_{i}.TempCondOut\"] = \"TempCondOut\"\n",
    "    renaming[f\"CT_{i}.PerFreqFan\"] = \"PerFreqFan\"\n",
    "    renaming[f\"CT_{i}.PowFan\"] = \"PowFan\"\n",
    "    renaming[f\"CT_{i}.FlowCond\"] = \"FlowCond\"\n",
    "    renaming[f\"CT_{i}.PerFreqConP\"] = \"PerFreqConP\"\n",
    "    renaming[f\"CT_{i}.PowConP\"] = \"PowConP\"\n",
    "    renaming[f\"CT_{i}.PressDiffCond\"] = \"PressDiffCond\"\n",
    "    renaming[f\"CH_{i}.PowChi\"] = \"PowChi\"\n",
    "    renaming[f\"CH_{i}.Tonnage\"] = \"Tonnage\"\n",
    "    renaming[f\"Chiller_{i} chillerEvapEnteringWaterTemp\"] = \"TempEvapIn\"\n",
    "    renaming[f\"Chiller_{i} chillerEvapLeavingWaterTemp\"] = \"TempEvapOut\"\n",
    "    renaming[f\"Chiller_{i} chillerEvapWaterFlow\"] = \"FlowEvap\"\n",
    "    renaming[f\"Chiller_{i} outdoorAirHumidity\"] = \"PerHumidity\"\n",
    "    columns_to_keep = list(renaming.values())\n",
    "    if i==1:\n",
    "        df1.rename(renaming, inplace=True, axis=1)\n",
    "        df1 = df1[columns_to_keep]\n",
    "    else:\n",
    "        df2.rename(renaming, inplace=True, axis=1)\n",
    "        df2 = df2[columns_to_keep]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#27469c\">Cooling Tower 1</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the columns and create a separate figure for each\n",
    "for column in df1.columns[1:]:\n",
    "    plt.figure()  # Create a new figure\n",
    "    plt.plot(df1.index, df1[column])\n",
    "    plt.title(f'Trendline for {column}')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel(column)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_data_size = df1.shape[0]\n",
    "\n",
    "# drop columns with no data (FlowCond)\n",
    "df1 = df1.dropna(axis=1, how=\"all\")\n",
    "\n",
    "# replace 0.0 in enviroment columns with null\n",
    "env_cols = [\"TempWetBulb\", \"TempCondIn\", \"TempEvapOut\", \"TempEvapIn\", \"TempAmbient\", \"PerHumidity\"]\n",
    "df1[env_cols].replace({0.0 : np.nan}, inplace=True)\n",
    "\n",
    "print(df1.isna().sum() / df1.shape[0])\n",
    "\n",
    "df1 = df1.dropna()\n",
    "print(f\"After missing data removal, we are left with {df1.shape[0]} rows out of {initial_data_size}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add season, dayOfWeek and hourOfDay columns\n",
    "preprocessor.create_season_col(datadf=df1, season_col_name=\"Season\")\n",
    "df1[\"DayOfWeek\"] = df1.index.weekday\n",
    "df1['HourOfDay'] = df1.index.hour\n",
    "\n",
    "s2 = set(df1.columns)\n",
    "s1 = set(['FlowEvap', 'PerHumidity', 'TempAmbient', 'TempCondIn',\n",
    "       'TempCondOut', 'TempEvapIn', 'TempEvapOut', 'TempWetBulb',\n",
    "       'PerFreqConP', 'Tonnage', 'Season', 'DayOfWeek', 'HourOfDay',\n",
    "       'PerFreqFan', 'EnergyConsumption'])\n",
    "print(s2 - s1)\n",
    "print(s1-s2)\n",
    "\n",
    "# target\n",
    "\n",
    "df1['EnergyConsumption'] = df1[\"PowFan\"] + df1[\"PowConP\"] + df1[\"PowChi\"] # note that this summation is different for ESB\n",
    "df1.drop(columns=[\"PowFan\", \"PowConP\", \"PowChi\"], inplace=True)\n",
    "\n",
    "# # save tower 1 preprocessed data\n",
    "df1.sort_index(axis=1).to_csv(f'{rootpath}/data/kissam/kissam1_preprocessed.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#27469c\">Replicate for Cooling Tower 2</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing data\n",
    "initial_data_size = df2.shape[0]\n",
    "df2 = df2.dropna(axis=1, how=\"all\")\n",
    "df2[env_cols].replace({0.0 : np.nan}, inplace=True)\n",
    "print(df2.isna().sum() / df2.shape[0])\n",
    "df2 = df2.dropna()\n",
    "print(f\"After missing data removal, we are left with {df2.shape[0]} rows out of {initial_data_size}.\")\n",
    "\n",
    "# add season, dayOfWeek and hourOfDay columns\n",
    "preprocessor.create_season_col(datadf=df2, season_col_name=\"Season\")\n",
    "df2[\"DayOfWeek\"] = df2.index.weekday\n",
    "df2['HourOfDay'] = df2.index.hour\n",
    "df2['EnergyConsumption'] = df2[\"PowFan\"] + df2[\"PowConP\"] + df2[\"PowChi\"] # note that this summation is different for ESB\n",
    "df2.drop(columns=[\"PowFan\", \"PowConP\", \"PowChi\"], inplace=True)\n",
    "\n",
    "# save tower 2 preprocessed data\n",
    "df2.sort_index(axis=1).to_csv(f'{rootpath}/data/kissam/kissam2_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the columns and create a separate figure for each\n",
    "for column in df2.columns[1:]:\n",
    "    plt.figure()  # Create a new figure\n",
    "    plt.plot(df2.index, df2[column])\n",
    "    plt.title(f'Trendline for {column}')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel(column)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3-8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
