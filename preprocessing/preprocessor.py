import pandas as pd
import numpy as np
from typing import List
from scipy import stats


def remove_missing_data(
    datadf: pd.DataFrame,
    threshold: float = 0.03,
    initial_data_size: int = None,
    remove_generated: bool = True,
    verbose: bool = False,
):
    """
    Remove missing data from a DataFrame such that all completely empty columns are removed.
    If fraction of rows to remove is below the specified threshold, then rows are also removed
    else must be done manually/must follow data imputation methods.

    Args:
        datadf (pandas.DataFrame): Input DataFrame.
        threshold (int): Threshold of fraction of rows that may be removed.
        initial_data_size (int): Initial size of dataframe for logging purposes.
        remove_generated (bool): Whether to remove columns generated by data collection API

    Returns:
        pandas.DataFrame: DataFrame with outliers removed.
    """
    if not initial_data_size:
        initial_data_size = datadf.shape[0]

    # remove any columns generated by api
    if remove_generated:
        datadf = datadf[[col for col in datadf.columns if "generated" not in col]]
    # remove all columns that are completely empty
    datadf = datadf.dropna(axis=1, how="all")

    # percentages of missing data in each column:
    missing_info = datadf.isna().sum() / datadf.shape[0]
    if verbose:
        print(missing_info)
    # only a few rows are empty so drop them
    if all(value < threshold for value in missing_info):
        datadf = datadf.dropna()
        if verbose:
            print(
                f"After missing data removal, we are left with us with {datadf.shape[0]} rows out of {initial_data_size}."
            )
        return datadf
    else:
        if verbose:
            print(
                f"Manual missing data handling required: Removed empty columns, but there more than {threshold*100}% missing data along the rows."
            )
    return datadf


def remove_outliers_std(
    datadf: pd.DataFrame,
    has_off_data: bool,
    column_names: List[str] = None,
    threshold: int = 3,
    on_condition: pd.Series = None,
    verbose: bool = False,
):
    """
    Remove outliers from a DataFrame using standard deviation method.

    Args:
        datadf (pandas.DataFrame): Input DataFrame.
        columns (list): List of column names to check for outliers.
        threshold (float): Standard deviation threshold to determine outliers. Default is 3.

        To exclude times when the cooling tower was off while calculating outliers so that
        zeroes don't interfere with calculation, pass in a dataframe that excludes off columns.

    Assumption: There is no negative valued data.

    Returns:
        pandas.DataFrame: DataFrame with outliers removed.
    """

    # checking inputs
    if has_off_data and on_condition is None:
        print(
            "If you want to have data from when the tower was off, you must provide a condition for when it was on."
        )
        return
    if not has_off_data and on_condition is not None:
        print(
            "If you don't have data from when the tower was off, the condition for when it was on is not needed."
        )

    # providing default values to inputs
    if not has_off_data:
        on_condition = pd.Series([True] * datadf.shape[0])
    if not column_names:
        column_names = datadf.select_dtypes(include=[int, float]).columns.to_list()

    filtered_df = datadf.copy()
    for column_name in column_names:
        # on_condition will exclude zeroes from when the tower was off during calculations
        std = filtered_df[on_condition][column_name].std()
        mean = filtered_df[on_condition][column_name].mean()

        cutoff = std * threshold
        lower_bound = mean - cutoff
        upper_bound = mean + cutoff

        # if off data is present then lower bound is not used (because there are many zero values)
        if has_off_data:
            if verbose:
                print(
                    f"{column_name} has {filtered_df[(filtered_df[column_name] < 0) | (filtered_df[column_name] > upper_bound)].shape[0]} outliers"
                )

            filtered_df = filtered_df[
                (filtered_df[column_name] >= 0)
                & (filtered_df[column_name] <= upper_bound)
            ]

        # if off data is not present then lower bound is used
        else:
            filtered_df = filtered_df[
                (filtered_df[column_name] >= lower_bound)
                & (filtered_df[column_name] <= upper_bound)
            ]

    if verbose:
        print(
            f"Outier removal removed {datadf.shape[0] - filtered_df.shape[0]} rows ({(datadf.shape[0] - filtered_df.shape[0]) / datadf.shape[0] * 100}% of data) with outliers. Now left with {filtered_df.shape[0]} rows."
        )

    return filtered_df


def get_correlation_info(df1: pd.DataFrame, df2: pd.DataFrame):
    """
    Create a dataframe of correlations between columns of the two dataframes

    Args:
        df1 (pandas.DataFrame): Input DataFrame.
        df2 (pandas.DataFrame): Input DataFrame.

    Returns:
        pandas.DataFrame: DataFrame with correlations between columns of the two dataframes with df1 columns along the rows (left) and df2 columns along the columns (top).
    """
    correlations = (
        df1.select_dtypes(include=[int, float])
        .merge(df2.select_dtypes(include=[int, float]), on=df1.index)
        .corr()
    )
    correlations.drop(
        df1.select_dtypes(include=[int, float]).columns, axis=1, inplace=True
    )
    correlations.drop(
        df2.select_dtypes(include=[int, float]).columns, axis=0, inplace=True
    )
    return correlations


def create_efficiency_col(
    datadf: pd.DataFrame,
    enteringWaterTemp: str,
    leavingWaterTemp: str,
    outdoorAirWetBulb: str,
    efficiency_col_name: str = "efficiency",
):
    """
    Add a column of efficiency values

    Args:
        datadf (pandas.DataFrame): Input DataFrame.
        enteringWaterTemp (str): Name of the entering water temperature column.
        leavingWaterTemp (str): Name of the leaving water temperature column.
        outdoorAirWetBulb (str): Name of the outdoor air wet bulb column.
        efficiency_col_name (str): Desired name of the new efficiency colummn

    Returns:
        pandas.DataFrame: DataFrame with correlations between columns of the two dataframes with df1 columns along the rows (left) and df2 columns along the columns (top).
    """
    # temperature of water leaving at next time
    nextLeavingWaterTemp = datadf[leavingWaterTemp].shift(periods=-1)

    # wet bulb temperature average between current and next time
    nextWetBulbAverage = datadf[outdoorAirWetBulb].rolling(2).mean().shift(-1)

    # create efficiency column
    datadf[efficiency_col_name] = abs(
        (datadf[enteringWaterTemp] - nextLeavingWaterTemp)
        * 100
        / (datadf[enteringWaterTemp] - nextWetBulbAverage)
    )

    # last row has a nan value for wet bulb average, so last row of efficiency will also be nan
    datadf.drop(datadf.index[-1], inplace=True)


def create_season_col(
    datadf: pd.DataFrame, season_col_name: str, time_col_name: str = None
):
    """
    Add a column of efficiency values

    Args:
        datadf (pandas.DataFrame): Input DataFrame.
        time_col (str): Desired of the new season column
        time_col (str): Name of the datetime column

    Returns:
        pandas.DataFrame: DataFrame with correlations between columns of the two dataframes with df1 columns along the rows (left) and df2 columns along the columns (top).
    """

    if time_col_name:
        time_col = datadf[time_col_name]
    else:
        time_col = datadf.index

    datadf[season_col_name] = time_col.month.map(
        lambda x: "spring"
        if x in [3, 4, 5]
        else "summer"
        if x in [6, 7, 8]
        else "fall"
        if x in [9, 10, 11]
        else "winter"
    )
